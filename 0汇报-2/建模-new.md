# 面向公平性的云边微服务系统部署方法

### Deployment Methods for Cloud - Edge Microservice Systems Oriented towards Fairness

### A. 场景描述

在某些**高实时性应用**服务中，用户分布广泛，涵盖城市中心的用户与偏远地区的用户，他们通过各种终端设备接入系统以请求服务。为了提升服务质量，本研究采用**云-边协同计算架构**，即在多个地理位置部署**边缘服务器**，同时依托**云服务器**提供计算支持，以减少计算任务的远程传输延迟，提高系统的整体响应效率。

在该架构下，如何确保**不同用户在资源受限的环境下获得公平的服务体验**是核心挑战。**用户服务体验的核心衡量指标是响应时间**，即用户从发送请求到接收到服务响应所经历的时间。本研究中的**公平性问题**主要体现在如何在**资源受限的环境**下，确保不同用户在获得计算资源和网络资源时能够享受**相对公平的响应时间**。具体而言，公平性问题可划分为以下两个层面：

**1. 同优先级用户间的公平性**

在**相同优先级**的用户群体内，地理位置不同导致其**网络条件存在显著差异**。接近边缘服务器的用户通常具有较低的传输延迟，而远离边缘服务器的用户则可能面临更高的传输延迟，从而影响**同优先级用户的响应时间公平性**。

* **公平性目标**：在相同优先级的用户之间，尽可能**均衡响应时间**，避免因网络环境因素导致服务体验的不均衡，从而实现相对公平的服务分配。

**2. 跨优先级用户的公平性**

在实际应用中，用户通常按照不同的**服务优先级**进行分类，例如**普通用户**、**VIP 用户**等。**高优先级用户**通常为付费用户，他们期望获得**更短的响应时间**和**更稳定的服务体验**。因此，在资源受限的边缘计算环境中，**系统无法保证所有用户均能获得最优的服务质量**，必须在公平性与服务等级保障之间进行权衡。

* **公平性目标**：确保在资源受限的环境下，**高优先级用户的平均响应时间优于低优先级用户**，即优先满足高优先级用户的计算和网络需求，以保障其**始终享有更优的服务体验**，同时在保证优先级机制有效性的前提下，尽可能避免低优先级用户的极端服务劣化。

**总结**

本研究旨在设计一种**面向公平性的云-边微服务部署优化策略**，以提高云-边协同计算的公平性和资源利用效率。在**资源受限环境**下，实现以下优化目标：

1. **同一优先级用户的公平性**：确保**相同优先级的用户**在不同地理位置和网络条件下，获得尽可能**均衡**的服务响应时间，避免因网络环境差异导致体验不均衡。

2. **跨优先级用户的服务保障**：在资源受限情况下，优先保障高优先级用户的服务质量，使其平均响应时间始终优于低优先级用户，确保资源分配符合优先级策略。

3. **微服务的动态部署**：根据不同服务器的计算能力、网络延迟、带宽等因素，合理部署微服务实例，最大化资源利用率，并降低计算和通信成本。

### B. 系统建模

本文研究**云-边协同环境**下的**公平性优化微服务部署问题**。系统由一组**边缘服务器**（记作 $S_{edge}$）和**公有云平台**（记作 $S_{cloud}$）组成，其中边缘服务器由系统完全控制，而云平台采取**按需计费**模式提供服务资源。用户请求的服务将由系统上中**部署的服务实例**进行处理。根据用户的**优先级**以及用户**请求的大小**，系统会根据不同策略为用户分配不同的**带宽和计算资源**，从而影响用户获取服务的**响应时间**。

在本系统中，每个用户请求的**处理优先级**会对其**资源分配**产生直接影响。高**优先级**的用户可能会优先获得更多的计算和带宽资源，从而减少其响应时间；而**低优先级**的用户可能会在资源紧张时面临较长的等待时间。为了保证系统的公平性和资源的高效利用，需要综合考虑各类用户的需求、优先级以及当前可用资源，动态调整资源分配策略。

系统会根据当前网络状况、带宽利用情况、计算负载以及服务实例的部署情况来优化资源的分配。例如，在边缘服务器**资源充足时**，优先处理高优先级用户的请求；而在边缘资源不足时，可能会将部分低优先级用户的服务请求发送到云服务器，以保证高优先级用户的服务质量。

此外，用户的请求不仅依赖于服务器的资源分配，还受到网络延迟等外部因素的影响。这些因素与用户请求的资源量、服务器的负载情况共同决定了最终的响应时间。因此，如何在多变的网络环境中平衡资源分配、用户优先级和响应时间，达到公平性优化的目标，是本系统研究的核心问题之一。

接下来，我们将对系统进行详细的建模，分析系统中各个组成部分之间的交互关系，以及如何在此基础上实现公平性优化。



#### **定义 1（用户与服务请求）**

设 $U$ 为系统中的用户集合，每个用户 $u_i \in U$ 具有以下属性：
$$
u_i = \langle  loc_i^{u}, L_i, W_i, q_i \rangle
$$
其中：

* $loc_i^{u}$：用户所处的位置，分为城市中心用户和边缘地区用户。

* **$L_i$**：用户的**优先级**（取值为 $1,2,3, \cdots$），数值越大表示用户的重要程度越高
  * **$W_i = f(L_i)$** ：表示用户的**权重**，与 $L_i$ 成正相关，表示不同优先级用户对应的计算加权值，在资源分配与带宽分配以及最后公平性指标计算时进行加权，以保障用户获取的服务质量与其优先级匹配。
  * 因为不同层级的用户，一般是有用户协议规定不同层级的 SLA 的，SLA 一旦已知了，那么系数就是已知的。

* **$q_i = <D_i^{in}, D_i^{out}, p_i>$**：表示用户的请求集合
  * $D_i^{in}$ 为该请求需要**上传**数据量（MB / s）；
  * $D_i^{out}$ 为该请求**返回结果**的数据量（MB / s）；
  * $p_i$ 为该请求的**任务量大小**（CU）。

用户请求的服务需要被分配到某台**边缘服务器**或**云端**进行处理。



#### 定义2（微服务）

设 $m$ 为系统提供的微服务（在本研究的场景中，系统只提供一种微服务），微服务的具体属性如下：
$$
m = \langle P^m, r^m \rangle
$$
其中：

* **$P^m$**：表示 $m$ 的**计算能力**（CU / s），即**每个服务实例**单位时间可处理的计算单位数。
* **$r^m$**：表示运行 $m$ 的服务实例所需的**计算资源**（RU）。





#### 定义3（边缘服务器）

每个**边缘服务器** $s_j^{edge} \in S_{edge}$ 具有以下属性：
$$
s_{j}^{edge} = < R_j^e,b_j^e, c_{fixed_j}^e>
$$
其中：

* $R_j^{e}$ ：表示边缘服务器 $s_j$ 提供的**可用计算资源**（包括$CPU 、RAM$ 等），假设 1 单位计算资源可提供 1 单位计算能力；
* $b_j^e$ ：表示边缘服务器 $s_j$ 的最大可用带宽，本研究中设定服务器的上下行带宽总量相同；
* $c_{fixed_j}^e$ ：表示租赁一台服务器 $s_j$ 的固定成本。

在本系统中，用户终端与边缘服务器之间的**网络带宽**和**通信延迟**分别表示为：
$$
B^e = \{ b_{ij}^e | \forall u_i \in U, \forall s_j \in S_{edge}  \}
$$

$$
D^e = \{ t_{d_{ij}}^e | \forall u_i \in U, \forall s_j \in S_{edge}  \}
$$

###### 边缘服务器的带宽分配方案

在边缘计算环境中，用户与边缘服务器之间的网络带宽有限，尤其当多个用户同时访问同一台边缘服务器时，**服务器的总带宽需在各用户之间合理分配**。为了兼顾用户请求的**数据量需求**与其**服务优先级**，本研究采用**按权重比例划分**的方式进行带宽分配：即综合考虑用户请求所需传输数据量与用户的优先级权重，从而实现**资源的公平且有效利用**。

* 该方式的核心思想是：在**总带宽不变**的前提下，用户请求的传输带宽越大、优先级越高，其应分配的带宽比例越高；反之，优先级较低或传输量较小的用户获得的带宽相对较少。这种机制可以在资源受限的边缘环境中，**提升高优先级任务的处理效率，同时也避免了带宽资源的极端倾斜**。

* 具体而言，用户 $u_i$ 与边缘服务器 $s_j$ 之间的实际可用带宽 $b_{ij}^e$ 可通过以下公式计算：：
  $$
  b_{ij}^e = \frac{W_i \cdot D_i}{\sum_{u_k \in U}x_{kj} \cdot W_k \cdot D_k } \cdot b_j^e
  $$
  其中，$x_{ij}$ 为用户请求与服务器之间的路由关系，其具体定义在见下面**定义 4**；$D_i = D_i^{in} + D_i^{out}$  即用户 $u_i$ 请求的交互数据量大小。

  

###### 边缘服务器计算能力分配

系统中，边缘服务器 $s_j$ 分配给用户 $u_i$ 的计算能力根据以下公式进行计算：
$$
P_{ij}^e = \frac{W_i \cdot p_i}{\sum_{u_k \in U} W_k \cdot p_k } \cdot \sum_{s_j \in S_{edge}} \lfloor \frac{R_j^e}{r^m} \rfloor \cdot p^m \cdot \eta
$$



#### 定义4 云平台

系统中的公有云平台 $S_{cloud}$ 具有以下属性 ：
$$
s_{cloud} = < P^c, p_{net}>
$$
其中，

* $P^c$ 表示云服务器为发送到其上的服务请求提供的计算能力。由于本研究场景云服务器计算资源丰富，可提供充足的计算能力，故设定云服务器为发送到其上的服务请求提供的计算能力为定值，通常情况下$$P^c > P_{ij}^e$$。
* $p_{net}$ 表示在云服务器上处理服务请求**消耗单位计算资源**的价格。



系统中**用户终端**与**云服务器**之间的**网络带宽**和**通信延迟**分别表示为：
$$
B^c = \{ b_{i}^c | \forall u_i \in U  \}
$$

$$
D^c = \{ t_{d_{i}}^c | \forall u_i \in U \}
$$

不同用户与云服务器间的网络带宽与通信延迟值不同，该值由系统随机生成。由于云服务器与边缘服务器相比距离用户较远，故其通信延迟往往较大，即 $t_{d_{i}}^c > t_{d_{ij}}^e$



#### 定义5 （路由方案）

路由方案 **X** 描述了系统中**用户服务请求与服务器的关系**，用二维数组来表示：
$$
X = \{ x_{ij} | \forall u_i \in U,s_j \in S,  x_{ij} \in \{0,1\} \}
$$
其中， $x_{ij}$ 表示用户 $u_i$ 是否发送请求到服务器 $s_j$ ：
$$
x_{ij} = 
\begin{cases} 
  1, & \text{用户} u_i \text{发送请求到服务器} s_j \\
  0, & 否则
\end{cases}
$$



#### 定义6（微服务部署方案）

**微服务部署方案** **Y** 描述了**微服务实例在服务器上的部署状态**：
$$
Y = \{ y_{j} | s_j \in S_{edge}, y_j \in \mathbb{N} \}
$$
其中，$y_{j}$ 表示在边缘服务器 $s_j$ 上运行的**服务实例数量**。在微服务架构中，通过在多个节点上运行服务的多个实例来实现负载均衡，每个节点可以托管服务的多个实例。

### C. 问题形式化表达

在前述的**系统建模**过程中，我们定义了云-边协同架构下的**各类服务器、服务实例、用户请求及其相关资源分配**的基本构成与关系。接下来，为了深入分析如何在该架构下优化微服务部署的公平性，我们将进一步对系统中的优化问题进行形式化表达，并明确问题的目标和约束条件。

#### 1）响应时间

设 $t_{ij}$ 为连接到服务器 $s_j$ 的用户 $u_i$ 获取服务的响应时间，包括三部分，数据**传输延迟 $t_{send_{ij}}$、处理延迟 $t_{p_{ij}}$ 及传播延迟 $t_{d_{ij}}$**：
$$
t_{ij} = t_{send_{ij}} + t_{p_{ij}} + t_{d_{i,j}}
$$

由于边缘服务器与云服务器的差异，其响应时间的计算方式也有所不同，如下。



##### a. 边缘服务器响应时间 $t_{ij}^e = t_{send_{ij}}^e + t_{p_{ij}}^e + t_{d_{i,j}}^e$

- **传输延迟 $t_{send_{ij}}^e = \frac {D_i }{b_{ij}^e}$** 
  - 表示传输**数据量**与用户服务器之间的**带宽**比


* **处理延迟** $t_{p_{ij}}^e = \frac{p_{i}}{P_{ij}^e}$
* 为处理请求需要的**总计算单位**与**服务实例分配给用户**的**计算能力**之比
* **传播延迟** $t_{d_{ij}}^e$

  * 即前面定义的用户与**边缘服务器**之间的基础**传播延迟**



##### b. 云服务器响应时间 $t_{ij}^c = t_{send_{ij}}^c + t_{p_{ij}}^c + t_{d_{i}}^c$

- **传输延迟 $t_{send_{ij}}^c = \frac {D_i}{b_{i}^c}$** 
  - 表示传输**数据量**与用户服务器之间的**带宽**比


* **处理延迟** $t_{p_{ij}}^c = \frac{p_{i}}{P^c}$
* 为处理请求需要的**总计算单位**与**云服务器**的**计算能力**之比


* **传播延迟** $t_{d_{i}}^c$
  * 即前面定义的用户与**云服务器**之间的基础**传播延迟**

即，用户 $u_i$ 连接到服务器 $s_j$ 请求服务的总响应时间为：
$$
t_{ij} =
\begin{cases} 
  \frac {D_i}{b_{ij}^e} + \frac{p_{i}}{P_{ij}^e} + t_{d_{ij}}^e, & \text{用户}{发送请求到边缘服务器} s_j \\
  \frac {D_i}{b_{i}^c} + \frac{p_{i}}{P^c} + t_{d_{i}}^c, & \text{用户}{发送请求到云服务器}
\end{cases}
$$



#### 2）总成本 Cost

系统总的部署成本 $Cost$ 由**租赁边缘服务器的成本 $C_{edge}$ **以及**使用云服务器计算资源的成本 $C_{cloud}$** 两部分组成。

##### a. 边缘服务器成本

租赁边缘服务器的成本 $C_{edge}$ 为租赁的所有边缘服务器的价格的总和，计算公式如下：
$$
C_{edge} = \sum_{s_j \in S_{edge}} c_{fixed_j}^e
$$

##### b.云服务器成本

使用云服务器计算资源的成本 $C_{cloud}$ 即，其处理发送到云服务器的所有请求消耗的计算资源与单位计算资源价格的乘积，计算公式如下：
$$
C_{cloud} = \sum_{u_i \in U, s_j \in S_{cloud}} p_{net} \cdot p_i \cdot x_{ij}
$$

##### c. 总成本

$$
Cost = \sum_{s_j \in S_{edge}} c_{fixed_j}^e + \sum_{s_j \in S_{edge}} c_{fixed_j}^e
$$



#### 3）公平性目标函数 - 加权 Jain 公平性指数

为衡量系统的响应时间公平性，本研究设计所有用户加权响应时间的 Jain 公平性指数为公平性目标函数。 $F_{\text{Jain}}$ 定义如下：
$$
F_{\text{Jain}} = \frac{\left( \sum_{i=1}^{n} t_{ij}^{weight} \right)^2}{n \cdot \sum_{i=1}^{n} \left(t_{ij}^{weight}\right)^2}
$$

其中，$t_{ij}^{weight} = t_{ij} \cdot W_i$ ，为用户 $u_i$ 的加权响应时间；n 为用户总数。

* **公式解释**：    

  * **分子**：所有用户加权响应时间的**总和平方**，反映响应时间的**集中程度**，值越大说明加权时间分布越均衡。

  * **分母**：所有用户加权响应时间的**平方和**，表示响应时间的离散程度，值越大说明时间差异较大。

  * 公式整体衡量了加权响应时间的均衡性，指数越**接近 1**，表明系统越公平。

  

* **加权作用**：      

  * **影响分子**：**高权重**用户的**短响应时间**有助于**拉近用户间的加权响应时间**，提高公平性。

  * **影响分母**：**高权重**用户的**短响应时间**降低**分母增长速度**，使指数**更接近 1**。

  

* **作用分析**：

  * **提升同优先级用户的公平性**：加权 Jain 指数的最大化保证了**相同优先级**用户的加权响应时间接近，从而减少同级用户间的响应时间差异，提高系统内部的公平性。

  * **保障高优先级用户的低响应时间**：在资源受限的情况下，权重机制确保高优先级用户获得更多计算资源，使其响应时间更短。

  * **整体公平性优化**：Jain 指数越大，说明系统既保证了**相同优先级**用户的响应时间相近，又确保了**跨优先级**用户的响应时间符合优先级设定，即优先级越高的用户响应时间越短，确保了整个系统响应时间的公平性。



#### 3）约束条件

##### 1. 不同优先级用户的平均响应时间约束

各优先级用户的平均响应时间不能超过其最大响应时间限制：
$$
\frac{1}{|U_{L_i}|} \sum_{u_j \in U_{L_i}} \sum_{s_k \in S} x_{jk} \cdot t_{jk} \leq T_{L_i}^{max}, \quad \forall L_i
$$

其中，$T_{L_i}^{max}$ 为优先级 $L_i$ 的用户的最大平均响应时间。



##### 2. 成本约束

系统中的成本不得超过成本预算 $C_{max}$：
$$
C_{edge}  + C_{cloud}  \leq C_{max}
$$


##### 3.  用户与服务器的连接约束

为确保所有用户的请求都被处理，每个用户 $u_i$ 必须连接到唯一一个服务器：
$$
\sum_{\forall s_j \in S} x_{ij} = 1, \quad  \forall u_i \in U
$$



##### 4. 服务实例计算能力约束

连接到同一服务器的所有用户的计算能力需求并不能超过**该服务器上**部署的服务实例的总计算能力：
$$
\sum_{u_i \in U} x_{ij} \cdot p_{ij} \leq y_j \cdot p^m, \quad \forall s_j \in S_{edge}
$$



##### 5. 边缘服务器计算资源约束

每个边缘服务器上的服务实例所需总资源不超过服务器可提供的资源：

$$
y_j \cdot r^m \leq R_j^{server}, \quad \forall s_j \in S_{edge}
$$



##### 6. 边缘服务器带宽约束

连接到边缘服务器的 $s_j$ 的所有用户的带宽总和不得超过该边缘服务器的最大可用带宽：
$$
\sum_{u_i \in U} x_{ij} ⋅ b_{i,j}^e \leq b_j^{e} , \quad \forall s_j \in S_{edge}
$$



#### 4）问题定义

在由 **私有边缘集群 $S_{edge}$ 和公共云 $S_{cloud}$** 组成的微服务系统中，目标是在 **满足各项约束条件** 的前提下 **优化用户与服务器连接关系 X 与微服务部署方案 Y **，以最大化系统的**公平性**。本研究采用 **用户响应时间** 作为衡量用户服务体验的关键指标，即通过最大化系统所有用户响应时间的**加权 Jain 指数**，优化不同用户在系统中的服务获得情况，从而提升整体公平性。

$$
max \quad F_{jain}
$$

$$
s.t. \quad \frac{1}{|U_{L_i}|} \sum_{u_j \in U_{L_i}} \sum_{s_k \in S} x_{jk} \cdot t_{jk} \leq T_{L_i}^{max}, \quad \forall L_i
$$

$$
C_{edge}  + C_{cloud}  \leq C_{max}
$$

$$
\sum_{\forall s_j \in S} x_{ij} = 1, \quad  \forall u_i \in U
$$

$$
\sum_{u_i \in U} x_{ij} \cdot p_{ij} \leq y_j \cdot p^m, \quad \forall s_j \in S_{edge}
$$

$$
y_j \cdot r^m \leq R_j^{server}, \quad \forall s_j \in S_{edge}
$$

$$
\sum_{u_i \in U} x_{ij} ⋅ b_{i,j}^e \leq b_j^{e} , \quad \forall s_j \in S_{edge}
$$

### D.优化问题求解

## FCGDO 

**Fairness - Centered Greedy Deployment Optimization（以公平性为核心的贪心部署优化算法）**



#### 总述

为解决本研究中面向公平性的云边微服务系统部署优化问题，本文提出了一种以公平性为核心的贪心部署优化算法 **FCGDO**。该算法面向复杂的云边协同环境，旨在显著提升系统部署的公平性与资源利用效率。

FCGDO 包含三个核心子算法：

* **算法 1：贪心服务请求路由算法**。遍历所有服务请求，基于**加权 Jain 指数最大化**原则选择最优服务器，兼顾资源约束，完成初**始请求分配**，并记录潜在影响公平性的请求连接。
* **算法 2：贪心迁移与公平性优化算法**。针对算法 1 中可能降低系统公平性的请求连接，通过**迁移**请求以提升整体加权 Jain 指数，实现分配方案的公平性优化。
* **算法 3：服务实例部署与调整算法**。根据优化后的路由方案**部署服务实例**，动态监测资源使用情况；在资源超载时，触发路由调整与重部署操作，确保部署可行性与系统稳定性。

### **算法 1：贪心服务请求路由**

| Algorithm 1: Fairness Centered Greedy Service Request Routing |
| :----------------------------------------------------------- |
| Require: Set of all requests $R$, Set of all servers $S$<br/>Ensure: Request assignment $A$, Set of requests reducing fairness $B$ |
| 1: $A \leftarrow \varnothing$, $B \leftarrow \varnothing$<br/>2: for $r \in R$ do<br/>3:     $u \leftarrow$ getUser($r$); $S_{avail} \leftarrow$ getAvailableServers($u$)<br/>4:     $s_{best} \leftarrow \text{null}$, $J_{max} \leftarrow -\infty$<br/>5:     for $s \in S_{avail}$ do<br/>6:         tempAssign($r$, $s$); $J_{cur} \leftarrow$ calcJainIndex(); revertAssign($r$, $s$)<br/>7:         if $J_{cur} > J_{max}$ then $s_{best} \leftarrow s$, $J_{max} \leftarrow J_{cur}$<br/>8:     end for<br/>9:     if $s_{best} \neq \text{null}$ then<br/>10:        assign($r$, $s_{best}$); if!checkConstraints($s_{best}$) then $s_{best} \leftarrow$ reselect($r$, $S_{avail}$)<br/>11:        $A[r] \leftarrow s_{best}$; if calcJainIndex() < prevJainIndex then $B \leftarrow B \cup \{r\}$<br/>12:    end if<br/>13: end for<br/>14: return $A$, $B$ |

##### 目的：

此算法旨在把**服务请求分配给服务器**，同时**最大化加权 Jain 指数**，以此保证请求分配的公平性。它会对每个请求进行遍历，选取能使 Jain 指数最大的服务器，并且检查服务器资源约束，记录会降低 Jain 指数的请求连接。

##### 运行过程：

1. 获取所有请求，初始化**请求分配结果**与使加权 Jain 指数**降低**的请求连接列表。
2. 针对每个请求，获取其所属用户以及该用户可用的服务器集合。
3. 对每个可用服务器进行**遍历**，临时分配请求并计算当前分配下的 Jain 指数，挑选出能**使加权 Jain 指数最大的服务器**。
4. 把请求分配给选中的服务器，更新服务器负载，检查资源约束，若不满足则重新选择服务器。
5. 记录请求分配结果，检查是否降低了 Jain 指数，**若降低则记录该请求连接**。
6. 返回**请求分配结果**与**使加权 Jain 指数降低的请求连接列表**。

##### 算法复杂度分析：

* **时间复杂度：**假设用户请求数量为 $n$，服务器数量为 $m$。对于每个请求，需要遍历其可用服务器，每次遍历要计算 Jain 指数。因此，时间复杂度为 $$O(n \times m)$$。
* **空间复杂度：**主要用于存储请求分配结果和降低 Jain 指数的请求连接列表，空间复杂度为 $O(n)$。

### **算法 2：贪心迁移与公平性优化**

| Algorithm 2: Greedy Migration For Fairness Optimization      |
| :----------------------------------------------------------- |
| Require: Set of all requests $R$, Set of all servers $S$, Request assignment $A$,  Bad Connections $B$<br/>Ensure: New request assignment $A'$ |
| 1: $A' \leftarrow \varnothing$, $J_{cur} \leftarrow$ calcJainIndex()<br/>2: for $r \in B$ do<br/>3:     $s_{best} \leftarrow \text{null}$, $J_{max} \leftarrow -\infty$<br/>4:     for $s \in S$ where $s \neq$ getCurrentServer($r$) do<br/>5:         tempMigrate($r$, $s$); $J_{temp} \leftarrow$ calcJainIndex(); revertMigration($r$, $s$)<br/>6:         if $J_{temp} > J_{max}$ then $s_{best} \leftarrow s$, $J_{max} \leftarrow J_{temp}$<br/>7:     end for<br/>8:     if $s_{best} \neq \text{null}$ then<br/>9:        migrate($r$, $s_{best}$); if!checkConstraints($s_{best}$) then $s_{best} \leftarrow$ reselect($r$, $S$)<br/>10:       $J_{new} \leftarrow$ calcJainIndex(); if $J_{new} > J_{cur}$ then $J_{cur} \leftarrow J_{new}$, $A'[r] \leftarrow s_{best}$ else revertMigration($r$,  $s_{best}$), $A'[r] \leftarrow$ getCurrentServer($r$)<br/>11:    else $A'[r] \leftarrow$ getCurrentServer($r$)<br/>12:    end if<br/>13: end for<br/>14: for $r \in R$ where $r \notin A'$ do $A'[r] \leftarrow$ getCurrentServer($r$)<br/>15: return $A'$ |

##### 目的：

该算法对那些**使加权 Jain 指数降低**的请求连接进行处理，通过**调整用户请求路由**来提升加权 Jain 指数，进而**优化请求分配的公平性**。

##### 运行过程：

1. 获取所有请求和可用服务器，计算**初始加权 Jain 指数**，初始化迁移后的请求分配结果。
2. 针对每个使 Jain 指数降低的请求，**遍历所有可用服务器**（不考虑当前所在服务器），临时迁移请求并计算临时迁移后的 Jain 指数，挑选出能**使 Jain 指数最大**的服务器。
3. 把请求迁移到最佳服务器，更新服务器负载，检查资源约束，若不满足则重新选择服务器。
4. 计算迁移后的 Jain 指数，若指数得到**改善**则**记录迁移后的分配结果**，反之则**回溯迁移**并记录原始分配结果。
5. 处理**未记录**的请求，记录**其原始分配**结果。
6. 返回迁移后的请求分配结果。

##### 复杂度分析

* **时间复杂度：**假设降低 Jain 指数的请求数量为 $k$，服务器总数为 $m$。对于每个降低 Jain 指数的请求，需要遍历所有服务器（除当前所在服务器），每次遍历要计算 Jain 指数。因此，时间复杂度为 $O(k \times M)$。
* **空间复杂度：**主要用于存储迁移后的请求**分配结果**，空间复杂度为 $O(n)$。



###  **算法3：服务实例部署算法**

| Algorithm 3: Service Instance Deployment For Fairness Centered Routing |
| :----------------------------------------------------------- |
| Require: Set of all requests $R$, Set of all servers $S$, Routing scheme $R_{scheme}$<br/>Ensure: Deployment plan $D$ |
| 1: $overload \leftarrow \text{false}$, $D \leftarrow \{s: 0 \mid s \in S\}$, resetLoads($S$)<br/>2: repeat<br/>3:     $overload \leftarrow \text{false}$<br/>4:     for $r \in R$ do<br/>5:         $s \leftarrow R_{scheme}[r]$; $R_{onS} \leftarrow$ getRequestsOnServer($s$, $R$)<br/>6:         $total \leftarrow$ calcTotalDemand($R_{onS}$); $num \leftarrow$ calcNumInstances($total$)<br/>7:         for $i = 1$ to $num$ do<br/>8:             if checkConstraints($s$) then deployInstance($s$), updateLoad($s$), $D[s] \leftarrow D[s] + 1$ else $overload \leftarrow \text{true}$, break<br/>9:         end for<br/>10:        if $overload$ then break<br/>11:    end for<br/>12:    if $overload$ then $R_{scheme} \leftarrow$ reselectRouting($R$, $S$, $R_{scheme}$), $D \leftarrow \varnothing$, resetLoads($S$)<br/>13: until!$overload$<br/>14: return $D$ |



##### 目的：

此算法依据**给定的路由方案**在服务器上**部署服务实例**，同时检查服务器资源约束，若出现超载情况则**重新选择路由策略并重新部署**。

##### 运行过程：

1. 获取所有请求和可用服务器，初始化**路由方案**与**部署计划**。
2. 把每个服务器的部署数量初始化为 0。
3. 进入循环，对**每个请求进行遍历**，获取其**对应的服务器**，计算该服务器上所有请求的**总资源需求**以及**所需实例数量**。
4. 对所需实例数量进行遍历，检查服务器资源约束，若**满足**则部署实例并更新服务器负载和部署数量，若**不满足**则标记存在超载情况并停止在该服务器上继续部署。
5. 若存在超载情况，则**重新选择路由策略**，**清空**部署方案和服务器负载状态，再次进行部署；若不存在超载情况，则说明部署成功，退出循环。
6. 返回**部署方案**。

##### 算法复杂度分析：

* **时间复杂度：**假设用户请求数量为 $n$，服务器总数为 $m$，每个服务器上所需实例的平均数量为 $l$。在最坏情况下，可能需要多次重新选择路由策略，每次重新部署需要遍历所有请求和实例。因此，时间复杂度为 $O(n \times l \times M)$
* **空间复杂度：**主要用于存储部署计划，空间复杂度为 $O(m)$。



### **总结**

##### FCGDO 算法总流程：

**首先**，贪心服务请求路由算法将服务请求分配给服务器，以最大化加权 Jain 指数来保证分配公平性，并记录降低公平性的请求连接。**接着**，贪心迁移与公平性优化算法对降低公平性的请求连接进行迁移处理，进一步提升请求分配的公平性。**最后**，服务实例部署算法依据优化后的请求分配结果，在服务器上部署服务实例，同时检查资源约束，确保部署合理且不超载 。整个体系围绕公平性展开，提升了系统的公平性与资源利用效率 。

##### 整体复杂度：

三个算法是顺序执行，整体复杂度取决于时间复杂度最高的算法，即 $O(n \times l \times M)$；整体空间复杂度为 $O(n + M)$。