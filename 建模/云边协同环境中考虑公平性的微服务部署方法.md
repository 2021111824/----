# 云边协同环境中考虑公平性的微服务部署方法
## 1. 概述
随着云端丰富的计算资源以及边缘服务器低延迟特性的不断发展，微服务系统与云-边协同计算已广泛应用于各类场景中。然而，现有的研究主要集中于调整微服务系统部署方案，以最大化整体用户的服务质量体验（QoE），而往往忽略了不同用户之间QoE差异，即公平性问题。这种差异可能导致部分用户的服务质量显著下降，不利于整体用户体验的一致性。 

为了解决这一问题，本文提出了一种新的部署优化方法，旨在**尽量降低总体响应时间**、提升整体用户体验的基础上，**最小化不同用户之间的响应时间差异，以实现公平性目标**。同时，本文以**部署成本**为主要约束条件，确保系统的经济可行性，并在各个实例节点上设定合理的**计算资源限制**，避免资源超载问题。 

通过这样的优化框架下，我们可以在云边协同环境中实现微服务的公平部署，缩小用户体验差异并满足合理的成本控制和资源约束。这不仅有助于提升用户的整体满意度，还能促进微服务系统在更多场景中的有效应用。

* 要考虑的问题：
  * 服务实例的分布（确保不同位置的用户请求不会因为位置差异而导致显著的响应时间差异）；
  * 负载均衡（通过负载均衡以及智能调度，将用户请求分配到响应最快的服务实例上，避免某些服务因为负载过高而延迟增加）；
  * 资源配置（如计算能力以及内存，避免实例间因性能差异导致响应时间不平衡）。
  * 默认一个边缘节点就是指一个边缘服务器，一个边缘节点上部署一个服务实例。（这个貌似不太合理？一个边缘节点要部署多个么？）
  
## 2. 问题定义
### 2.1 场景描述
作为微服务部署提供商，我们负责为一家全国范围的视频流媒体服务公司设计和优化其服务架构。该公司面向广泛的用户群体，用户分布在不同的城市。

为了实现低延迟的视频播放服务，我们建议采用**云边协同架构**，在各地设置边缘节点，同时在云端整合丰富的计算资源。  

**边缘节点**位于用户附近，可以快速响应用户请求，降低物理传输带来的延迟，但由于各边缘节点的资源（如CPU和内存）有限，负载过高时会导致响应时间增加。**云端**拥有丰富的计算资源，但用户访问云端的延迟较高。因此，公司需要在云端和边缘节点之间合理部署服务实例，确保在不超过预算的前提下，最大化利用现有资源，让不同地区的用户获得尽量一致的响应时间体验。  

在此场景中，我们的目标是通过服务实例的智能部署，**尽量降低总体响应时间**并**最小化不同地区用户之间的响应时间差异**。在追求**公平性**的同时，控制边缘节点的**部署成本**和**计算资源**负载，避免边缘节点因超载影响用户体验。  

通过这样的优化方案，我们希望能够在实现公平性的同时，提升用户的整体满意度，并保证系统的经济可行性和资源的高效使用。



### 2.2 建模
#### 2.2.1 定义变量
a. **用户集 $U$**：  
    $U = \{u_1, u_2, \cdots, u_n\}$，表示所有用户，不同用户可能处于不同的地理位置。  
  
b.  **服务实例集 $S$**：  
    $S = \{s_1, s_2, \cdots, s_m\}$，表示所有可部署微服务实例的节点位置，包含边缘节点 $S_{edge}$ 和云端节点 $S_{cloud}$。    

  * 是否在节点 $s_j$ 上部署服务实例由二进制变量 $y_j$ 控制。
    $y_j = 1$ 表示在 $s_j$ 上部署服务实例，否则不部署。

c. **请求数据大小** $D_i$：  
    请求数据大小 $D_i$ 是用户 $u_i$ 发往服务实例（云或边缘）的数据量。

d. **连接变量 $x_{ij}$**：  
    用二进制变量 $x_{ij}$ 表示用户 $u_i$ 是否连接到服务实例 $s_j$ 。
$$
x_{ij} = 
\begin{cases} 
  1 & 用户 u_i 连接到服务实例 s_j \\
  0 & 用户 u_i 没有连接到服务实例 s_j
\end{cases}
$$
  * 满足每个用户连接到唯一的服务实例（约束3）
  
  <br />

e.   **响应时间 $t_{ij}$**：  
   用 $t_{ij}$ 表示用户 $u_i$ 连接到服务实例 $s_j$ 的响应时间，由两部分组成，$t_{trans_{ij}}$ 和 $t_{proc_{ij}}$ 。
* **传输延迟 $t_{trans_{ij}}$**：  
  表示用户 $u_i$ 到服务实例 $s_j$ 的传输延迟，根据服务实例位于**边缘节点**还是**云节点**有所不同：

  * **边缘节点的传输延迟 $t_{trans_{ij}}^{e}$**：
  $$
  t_{trans_{ij}}^{e} = t_{d_{ij}}^{e} + t_{b_{ij}}^{e}
  $$
  其中：
  
  $$
  t_{d_{ij}}^{e} = \frac {d_{ij}^{e}}{v_e}
  $$  

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  为**物理传输延迟**。$d_{ij}^{e}$ 表示用户 $u_i$ 到边缘节点 $s_j$ 的距离，$v_{e}$ 为边缘节点的网络传播速度。

  <br />

  $$
  t_{b_{ij}}^{e} = \frac {D_i}{b_e(t)}
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  为**带宽延迟**。${D_i}$ 是用户请求数据的大小，$b_c(t)$ 为边缘节点可用带宽，可能随时间变化。
  <br />
  <br />



  * **云节点的传输延迟 $t_{trans_{ij}}^{c}$**：
  $$
  t_{trans_{ij}}^{c} = t_{d_{ij}}^{c} + t_{b_{ij}}^{c}
  $$
  其中：
  
  $$
  t_{d_{ij}}^{c} = \frac {d_{ij}^{c}}{v_c}
  $$  

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  为**物理传输延迟**。$d_{ij}^{c}$ 表示用户 $u_i$ 到云节点 $s_j$ 的距离，$v_{c}$ 为边缘节点的网络传播速度，因为其物理距离更远，所以通常比边缘节点传播速度低。

  <br />

  $$
  t_{b_{ij}}^{c} = \frac {D_i}{b_c(t)}
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  为**带宽延迟**。${D_i}$ 是用户请求数据的大小，$b_c(t)$ 为云节点可用带宽，可能随时间变化。
  <br />
  <br />

* **处理时间** $t_{proc_{ij}}$：  
   $t_{proc_{ij}}$ 是服务实例处理请求的时间，取决于**请求数据大小**和服务实例的**处理速率**。处理时间计算也根据**边缘节点和云节点**的不同资源情况有所区别。

    * **边缘节点的处理时间 $t_{proc_{ij}}^{e}$**：
  $$
  t_{proc_{ij}}^{e} = \frac{D_{i}}{P_{j}^{e}} 
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;
  其中，$P_{j}^{e}$ 表示边缘节点 $s_j$ 的处理速率。

    * **云节点的处理时间 $t_{proc_{ij}}^{c}$**：
  $$
  t_{proc_{ij}}^{c} = \frac{D_{i}}{P_{j}^{c}}
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;
  其中，$P_{j}^{c}$ 表示云节点 $s_j$ 的处理速率。

  * 注：由于云节点的资源比边缘节点丰富，则应满足：
  $$
  P_{j}^{c} > P_{j}^{e}
  $$

* **综合响应时间计算**：  
   用户 $u_i$ 连接到服务实例 $s_j$ 的响应时间 $t_{ij}$ 为：

   * **若 $s_j$ 位于边缘节点**：
   $$
   t_{ij} = t_{trans_{ij}}^{e} + t_{proc_{ij}}^{e} = \left( t_{d_{ij}}^{e} + t_{b_{ij}}^{e} \right) + t_{proc_{ij}}^{e} = \left( \frac {d_{ij}^{e}}{v_e} + \frac {D_i}{b_e(t)} \right) + \frac{D_{i}}{P_{j}^{e}}
   $$

   * **若 $s_j$ 位于云节点**：
    $$
   t_{ij} = t_{trans_{ij}}^{c} + t_{proc_{ij}}^{c} = \left( t_{d_{ij}}^{c} + t_{b_{ij}}^{c} \right) + t_{proc_{ij}}^{c} = \left( \frac {d_{ij}^{c}}{v_c} + \frac {D_i}{b_c(t)} \right) + \frac{D_{i}}{P_{j}^{c}}
   $$

* **平均响应时间计算**：
$$
\bar{T}= \frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{m} x_{ij} \cdot \left( 
\begin{cases}
\left( \frac {d_{ij}^{e}}{v_e} + \frac {D_i}{b_e(t)} \right) + \frac{D_{i}}{P_{j}^{e}}, & s_j \in S_{edge} \\[10pt]
\left( \frac {d_{ij}^{c}}{v_c} + \frac {D_i}{b_c(t)} \right) + \frac{D_{i}}{P_{j}^{c}}, & s_j \in S_{cloud}
\end{cases}
\right)
$$

f.  **计算资源需求 $R_{i}$**  
用 $R_{i}$ 表示用户 $u_i$连接到服务实例 $s_j$时，服务实例需要分配的资源来处理视频流的请求。资源需求集合 $R_{i}$ 可定义为：
$$
R_{i} = \{r_{i}^{cpu}, r_{i}^{mem}, r_{i}^{b},  \cdots \}
$$

其中：  
* $r_{i}^{cpu}$ 表示用户 $u_i$连接到服务实例 $s_j$时所需的 $CPU$资源量；
* $r_{i}^{mem}$ 表示用户 $u_i$连接到服务实例 $s_j$时所需的 内存 资源量；
* $r_{i}^{b}$ 表示用户 $u_i$连接到服务实例 $s_j$时所需的 带宽 资源量。

<br />

g.   **部署实例成本 $c_j$**：  
  用 $c_j$ 表示在服务实例位置 $s_j$ 部署服务的成本，由于云节点和边缘节点的差异性，二者的部署成本也有所不同。
  * **边缘节点部署成本** $c_j^e$ ：
  $$
  c_{j}^e = c_{fixed}^e + c_{usage}^e
  $$
*
  * **固定成本** $c_{fixed}^e$ ：用于租赁边缘服务器（每个边缘节点的固定租赁费用）；
 
  * **资源使用成本** $c_{usage}^e$ ：是边缘节点在实际运行中产生的资源消耗成本，如 $CPU$、内存和带宽消耗，按资源占用进行计算：
  $$
  c_{usage}^e = \sum_{i = 1}^{n} x_{ij} \ \cdot (r_{i}^{cpu} \ \cdot p_{cpu}^{e} + r_{i}^{mem} \ \cdot p_{mem}^{e} + r_{i}^{b} \ \cdot p_{b}^{e})
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;
  其中，$p_{cpu}^{e}$ 、$p_{mem}^{e}$、$p_{b}^{e}$ 分别表示边缘节点上单位 $CPU$、内存和带宽资源的单价；$x_{ij}$ 表示用户 $u_i$是否连接到服务实例 $s_j$。

<br />

* **云节点部署成本** $c_j^c$ （云节点通常基于资源使用量付费，可以根据资源消耗量和处理请求数量来计算成本）：
  $$
  c_{j}^c = c_{usage}^c + c_{net}^c
  $$

*
  * **云资源使用成本** $c_{usage}^c$ ：按需计算，包括 $CPU$、内存和带宽使用量。
  $$
  c_{usage}^c = \sum_{i = 1}^{n} x_{ij} \ \cdot (r_{i}^{cpu} \ \cdot p_{cpu}^{c} + r_{i}^{mem} \ \cdot p_{mem}^{c} + r_{i}^{b} \ \cdot p_{b}^{c})
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;
  其中，$p_{cpu}^{c}$ 、$p_{mem}^{c}$、$p_{b}^{c}$ 分别表示云节点上单位 $CPU$、内存和带宽资源的单价；$x_{ij}$ 表示用户 $u_i$是否连接到服务实例 $s_j$。

  * **网络流量成本** $c_{net}^c$ ：用户从不同区域访问云，产生的额外网络传输费用，根据流量数据量计算。
  $$
  c_{net}^c = \sum_{i = 1}^{n} x_{ij} \ \cdot D_i \ \cdot p_{net}^{c}
  $$

  &nbsp;&nbsp;&nbsp;&nbsp;
  其中，$p_{net}^{c}$ 为云平台的流量单价，$D_i$ 为用户 $u_i$ 的数据请求的大小。


### 2.2.2 目标函数--多目标优化问题？
#### Ⅰ. 最小化用户响应时间差异（公平性）
通过**最小化用户响应时间的方差**，实现不同用户响应时间的一致性，从而提高用户体验的公平性。
* 公平性目标函数：用 $f_{1}$ 表示， 即
  $$
  f_{1} = \sum_{i=1}^{n} \sum_{j=1}^{n}((\sum_{k=1}^{m}x_{ik} ⋅ t_{ik}) - (\sum_{k=1}^{m}x_{jk} ⋅ t_{jk}))^2
  $$

#### Ⅱ. 最小化整体响应时间（或者也可以把它变成一个约束条件？给一个响应时间上限）
通过**最小化所有用户的平均响应时间**，提升整体用户体验
* 平均响应时间目标函数：用 $f_{2}$ 表示，即
$$
f_{2} = \bar{T} =  \frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{m} x_{ij} ⋅ t_{ij} 
$$


### 2.2.3 约束条件
#### 约束1：部署成本
* 用 $C_{edge}$ 表示边缘节点的总预算，用 $C_{cloud}$ 表示云端的总预算。两者的总和不得超过服务提供商的整体预算 $C_{max}$ 。
  $$
  \sum_{j \in S_{edge}} c_j^e ⋅ y_j \leq C_{edge}
  $$

  $$
  \sum_{j \in S_{cloud}} c_j^c ⋅ y_j \leq C_{cloud}
  $$

  $$
  C_{edge}  + C_{cloud} \leq C_{max}
  $$
  
  其中，$S_{edge}$ 为所有边缘节点集合，$S_{cloud}$ 为云端节点集合，$c_j$ 表示在节点 $s_j$ 上部署的成本，$y_j$ 为二进制变量，表示在节点 $s_j$ 是否部署服务实例，若部署则 $y_j = 1$， 否则 $y_j = 0$。

#### 约束2：边缘节点计算资源限制
* 每个边缘节点 $s_j$ 的资源消耗不超过其最大可用资源。
  $$
  \sum_{i=1}^{n} x_{ij} ⋅ r_{i}^{cpu} \leq R_j^{cpu\_max} , \forall j \in S
  $$

  $$
  \sum_{i=1}^{n} x_{ij} ⋅ r_{i}^{mem} \leq R_j^{mem\_max} , \forall j \in S
  $$

  $$
  \sum_{i=1}^{n} x_{ij} ⋅ r_{i}^{b} \leq R_j^{b\_max} , \forall j \in S
  $$

  其中，$R_j^{cpu\_max}$、$R_j^{mem\_max}$、$R_j^{b\_max}$ 分别为边缘节点 $s_j$ 的 $CPU$ 、内存和带宽的最大可用资源。

#### 约束3：用户与服务实例的连接
* 每个用户 $u_i$ 必须连接到唯一一个服务实例：
  $$
  \sum_{j=1}^{m} x_{ij} = 1, \forall i \in U
  $$
  确保每个用户的请求分配到一个最近或者响应时间最优的服务实例上。


### 2.2.4 模型表达
* 在Pareto优化框架下，模型表述为：
  $$
  \min f_{1} =  \sum_{i=1}^{n} \sum_{j=1}^{n}((\sum_{k=1}^{m}x_{ik} ⋅ t_{ik}) - (\sum_{k=1}^{m}x_{jk} ⋅ t_{jk}))^2  
  $$

  $$
  \min f_{2} = \frac{1}{n} \sum_{i=1}^{n} \sum_{j=1}^{m} x_{ij} ⋅ t_{ij}
  $$
  
  <br />

  $$
  subject\; to:  
  $$

  $$
  \sum_{j=1}^{m} c_j ⋅ y_j \leq C_{max}
  $$

  $$
  \sum_{i=1}^{n} x_{ij} ⋅ r_{ij} \leq R_j^{max} , \forall j \in S
  $$

  $$
  \sum_{j=1}^{m} x_{ij} = 1, \forall i \in U
  $$




## 3. 解决？
### 3.1 生成初始部署方案
注：初始部署方案先不考虑公平性，只是快速贪心出一个**满足资源约束**并且**尽可能降低响应时间**的基本部署方案。后续再迭代优化来实现公平性。  
* **节点优先级** $p_j$
  $$
  p_j = 
   \begin{cases} 
     n_j \times w_j & \text{若 } s_j \in S_{\text{edge}} \\
     \alpha \times w_j & \text{若 } s_j \in S_{\text{cloud}}
   \end{cases} 
  $$

  其中 ：   
  * $n_j$ 表示节点 $j$ 覆盖区域内的用户密度；
  * $w_j$ 表示节点 $j$ 覆盖区域内的流量需求权重（考虑请求频率、带宽需求等）  
  * $\alpha$ 为云端节点的优先级调整因子，设定为远小于 1，确保边缘节点优先；在资源不足时才考虑云端。
  
  根据优先级 $p_j$ 的值，对候选节点进行排序，形成**优先级由高到低的优先级序列** $S_{sorted}$ 。

* **服务实例初始分布**  
  将服务实例部署在**边缘和云端**节点上以覆盖所有高优先级的用户区域。若边缘节点资源受限，可将部分服务实例**移至云端**，以保证请求可被响应。  
  根据排序后的优先级列表 $S_{sorted}$ 部署服务实例，直到满足：
  $$
  \sum_{j \in S_{\text{sorted}}} y_j \geq K
  $$

  其中 ：   
  * $y_j$ 是二进制变量，表示节点 $j$ 是否部署了服务实例，若 $y_j = 1$ ，则在节点 $j$ 上部署了服务实例，否则没有；
  * $K$ 为需要部署的总服务实例数量。
  
* **用户连接关系**  
  确保每个用户 $u_i$ 连接到延迟最低的节点（包括边缘和云端节点），以保证初始方案下的**响应时间**最小化：
  
  $$
   t_{ij} = 
   \begin{cases} 
     t_{trans_{ij}}^{e} + t_{proc_{ij}}^{e}, & \text{若 } s_j \in S_{\text{edge}} \\
     t_{trans_{ij}}^{c} + t_{proc_{ij}}^{c}, & \text{若 } s_j \in S_{\text{cloud}}
   \end{cases}
  $$
  在初始部署方案中，用户 $u_i$ 首选最低延迟的**边缘节点**进行连接；若无边缘资源满足条件，则连接到云端节点。

* **边缘节点资源与连接限制**  
  注：假设云端节点资源不受约束。
  要确保每个服务实例能支持所有连接到它的用户。
  
  * **实例资源需求限制**  
    每个节点的资源需满足所有连接用户的需求，确保资源不会超载。

    $$
    \sum_{i=1}^{n} x_{ij} \cdot r_i^{\text{cpu}} \leq R_j^{\text{cpu\_max}}
    $$
    $$
    \sum_{i=1}^{n} x_{ij} \cdot r_i^{\text{mem}} \leq R_j^{\text{mem\_max}}
    $$
    $$
    \sum_{i=1}^{n} x_{ij} \cdot r_i^{\text{b}} \leq R_j^{\text{b\_max}}
    $$


  * **用户连接数量限制**：  
    （注：快速估算，可能不太准确。）    
    在实例资源需求限制的基础上，可以确定每个服务实例的最大用户连接数量为 $U_j^{max}$ ：

    假设用户的平均资源需求为 $\bar{r} = \{ \bar{r}^{\text{cpu}}, \bar{r}^{\text{mem}}, \bar{r}^{\text{b}} \}$，则边缘节点 $s_j$ 的最大用户连接数可以估算为：

    $$
    U_j^{\text{max}} = \min \left( \frac{R_j^{\text{cpu\_max}}}{\bar{r}^{\text{cpu}}}, \frac{R_j^{\text{mem\_max}}}{\bar{r}^{\text{mem}}}, \frac{R_j^{\text{b\_max}}}{\bar{r}^{\text{b}}} \right)
    $$

    根据该值，可以添加用户连接数量限制条件：
    $$
    \sum_{i=1}^{n} x_{ij} \leq U_j^{\text{max}}
    $$
    



















