# 关于资源分配与延迟

#### **计算发送时延（Transmission Delay）**

发送时延计算公式：
$$
T_{tx} = \frac{D}{B}
$$
其中：

* D 是数据包大小（bit）
* B 是可用链路带宽（bps）











![image-20250313111435805](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20250313111435805.png)





* 在线视频流场景







在云边协同计算环境下的微服务系统中，论文对资源需求和计算能力需求进行了如下定义：
1. **资源需求定义**：资源需求涉及多个方面，包括运行微服务实例所需的资源以及边缘服务器提供的资源。
    - **微服务实例资源需求**：对于每个微服务 $s_{i} $，其运行一个实例所需的资源表示为$r_{i}^{s}=<r_{i, 1}^{s}, r_{i, 2}^{s}, \cdots, r_{i, n}^{s}>$，这些资源包括CPU、RAM等。不同的微服务对资源的需求不同，例如，文中假设服务所需的计算资源以 “单位计算资源” 衡量，每个服务需要1 - 3单位的计算资源 。
    - **边缘服务器资源**：每个边缘服务器 $n_{i}$提供的可用资源集合表示为 $r_{i}^{n}=<r_{i, 1}^{n}, r_{i, 2}^{n}, \cdots, r_{i, m}^{n}>$ 。在实际场景中，每个边缘服务器的资源是有限的，如文中提到每个边缘服务器的计算资源在40 - 50单位之间。
2. **计算能力需求定义**
    - **微服务处理能力**：用$u_{i}$ 定义微服务 $s_{i}$ 的处理能力，它表示在保持服务质量的前提下，一个实例单位时间内能够处理的最大请求数 。例如，文中提到服务的平均处理能力为600，这意味着平均而言，每个服务实例在单位时间内最多能处理600个请求。
    - **云与边缘计算能力差异**：论文假设云的计算资源更为丰富，相同功能 $f_{i, j}$在云端的执行时间 $t_{i, j}^{p, C}$ 比在边缘服务器的执行时间 $t_{i, j}^{p}$ 更短，即$t_{i, j}^{p, C}<t_{i, j}^{p}$ 。这体现了云在处理计算任务时具有更强的计算能力，也影响了微服务在云边环境中的部署决策。 











你看我这样合不合理：假设边缘服务器有50单位计算资源，然后每个用户随机生成他需要多少计算资源，可能范围是1-3个单位，然后我们会对这个所需的计算资源按不同用户优先级的权重进行加权，然后计算该用户所需的计算资源占所有向服务器发出请求的计算资源的多少，按比例将计算能力分给该用户，然后根据这个计算能力来算该用户的处理时延？