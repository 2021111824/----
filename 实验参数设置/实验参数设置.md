#### 数据设置

* **边缘服务器**
  * 带宽：5000Mbps （5Gbps）
  * 计算能力：1000MB/s
  * 计算资源：100个单位
  * 延迟（用户到边缘服务器之间的传播时延）：10ms



* **云服务器**
  * 带宽：1000Mbps （1Gbps）
  * 计算能力：10000MB/s
  * 云服务器的计算资源充足
  * 延迟（用户到服务器之间的传播时延）：50ms



* **用户的数据请求量**

  * 1-10 MB/s

    

* **用户的带宽分配**

  * 先 1:1 用户的数据请求量，然后会按照不同优先级进行加权

  

* **用户的计算资源分配**

  边缘服务器分配给用户的计算资源为：
  $$
  r_i^{compute} = \alpha \cdot D_i \cdot W_i
  $$

  * 其中 $\alpha$ 是用户请求数据量与分配给该用户的计算资源量的转换系数，本实验中设定  $\alpha$ 为 0.05-0.1；

  * $W_{i}$ 为用户权重。

  

* **用户分配到的计算能力**

  连接到边缘服务器 $s_j$ 的用户 $u_i$ 分配到的计算能为：
  $$
  P_{ij}^{compute} = \frac{r_i^{compute}}{\sum_{u_k \in U} r_k^{compute}} \cdot P_j^{compute}, x_{kj} = 1
  $$

  * 即用户 $u_i$ 分配到的计算能力，为其分配到的计算资源占连接到该服务器的所有用户的计算资源**占比**乘以该**边缘服务器的总计算能力**。

  

#### 资源分配

资源分配的时候不用那么细，就分为两个部分

* **计算资源**（包含CPU、RAM等）

  * 这里面就不用再细分了，只是说有一个总量，比如50个单位，到时候按权重分配给用户就可以了；
  * 这个影响的是服务器的**计算能力**--即**处理时延**（请求数据量 / 服务器处理能力）

  

* **带宽**

  * 这个就是服务器有一定的总带宽，然后也是按权重分配给不同用户；
  * 这个就是影响**传输时延**（请求数据量 / 用户与服务器之间的带宽）

  

* 也就是说上面两部分应该都算是动态分配，不是固定死的



#### 关于时延

总时延 = 传输时延 + 传播时延 + 处理时延

* 传输时延：
  * 连接到**边缘服务器**的就是大家按优先级分可用带宽；
  * 连接到**云**的就是可用带宽比较小；
* 传播时延：
  * 都给一个常数
  * 云服务器的大一点；边缘服务器的小一点
* 处理时延：
  * 边缘和云都是各自的 数据量/计算能力